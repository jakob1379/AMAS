<!doctype html>
<html>
  <head>
    <meta content="text/html; charset=windows-1252" http-equiv="content-type" />
    <title>AdvancedMethodsAppliedStatistics</title>
    <meta http-equiv="refresh" content="300" />
  </head>
  <body>
    <h1>Advanced Methods in Applied Statistics 2018</h1>
    <br />
    <img
      src="assets/DJK.png"
      alt=""
    /><br />
    Lecturer: D. Jason Koskinen<br />
    Email: koskinen (at) nbi.ku.dk<br />
    <h2>Basic Information</h2>
    <ul>
      <li>
        Block 3 - Timetable A of the 2018
        <a
          href="http://www.science.ku.dk/english/student-life/studying-at-the-faculty/academic-calendar/"
          >academic calendar</a
        >
      </li>
      <ul>
        <li>Tues 08:00 - 12:00 and Thurs 08:00- 12:00 &amp; 13:00 - 17:00</li>
        <li>Actual</li>
        <ul>
          <li>08:00 - 08:30 student study time for both Tues. and Thurs.</li>
          <li>08:30 - 09:00 Q&amp;A or discussion with Jason in Aud. M</li>
          <li><b>09:00</b> lecture on new material (not 09:05 or 09:15)</li>
          <li>
            On Thursday there will very often be new material starting at 13:00
          </li>
          <li>
            On Thursday it is very unlikely that any new material, lectures, or
            review will happen after 16:00.
          </li>
        </ul>
      </ul>
      <li>Auditorium M at the Blegdamsvej campus</li>
      <li>
        Odd-numbered classes are 4-hours while even-numbered consist of 2 blocks
        of 4-hours
      </li>
      <li>
        Classes will be composed of ~20-30% lecture and demonstrations followed
        by exercise
      </li>
      <li>
        While assignments, projects, and exercises can be done in the
        programming language of the students choice, the examples and
        demonstrations will be mainly in Python and/or scientific packages
        thereof, i.e. SciPy, PyROOT, etc.
      </li>
      <li>Required text or textbooks: None</li>
      <li>
        2016 Advanced Methods in Applied Statistics
        <a
          href="../AdvancedMethodsInAppliedStatistics2016/AdvancedMethodsAppliedStatistics2016.html"
          >webpage</a
        >
      </li>
      <li>
        2017 Advanced Methods in Applied Statistics
        <a
          href="../AdvancedMethodsInAppliedStatistics2017/AdvancedMethodsAppliedStatistics2017.html"
          >webpage</a
        >
      </li>
      <li>
        <span style="color: #0000ee"></span>It is recommended, but not required,
        to have at least reviewed the little sibling to this course, i.e.
        "Applied Statistics - From data to results" which can be found
        <a
          href="http://www.nbi.dk/%7Epetersen/Teaching/AppliedStatistics2017.html"
          >here</a
        >
      </li>
    </ul>
    <h2><br /></h2>
    <hr />
    <h2>Evaluation</h2>
    <ul>
      <li>
        <span style="text-decoration: underline; font-weight: bold"
          >Oral presentation and 1-2 page summary</span
        >
        <a id="OralPresentation" name="OralPresentation"></a>(10%)
      </li>
      <ul>
        <li>
          ~10 minute summary presentation. Plan on ~7 slides if you are doing a
          PowerPoint-type presentation.
        </li>
        <li>Can work alone or in groups of up to 3.</li>
        <ul>
          <li>A 1-2 page summary including any and all group members names</li>
          <li>Presentation does NOT have to be given by all group members</li>
        </ul>
        <li>
          Talk or email with Jason if you have questions about the
          appropriateness of your article
        </li>
        <li>
          Be sure to put down which article you are using
          <a
            href="https://docs.google.com/spreadsheets/d/1tV6GgAVmbPyBjQ6OOxSsso011aQwZuyRxJ_1JTuhKY0/edit?usp=sharing"
            >here</a
          >
          to avoid duplication
        </li>
        <li>
          Example
          <a href="https:///OralPresentationExample_FiniteMonteCarlo.pdf"
            >presentation</a
          >
          on
          <a
            href="http://www.sciencedirect.com/science/article/pii/001046559390005W"
            >Finite Monte Carlo article</a
          >
        </li>
        <li>
          Other example articles (and no, you cannot use any of these articles
          for your report/presentation):
        </li>
        <ul>
          <li>
            Frequency Difference Gating: A Multivariate Method for Identifying
            Subsets That Differ Between Samples (<a
              href="http://onlinelibrary.wiley.com/doi/10.1002/1097-0320%2820010901%2945:1%3C56::AID-CYTO1144%3E3.0.CO;2-9/epdf"
              >article</a
            >)
          </li>
          <li>
            Probability binning comparison: a metric for quantitating
            multivariate distribution differences (<a
              href="http://onlinelibrary.wiley.com/doi/10.1002/1097-0320%2820010901%2945:1%3C47::AID-CYTO1143%3E3.0.CO;2-A/full"
              >article</a
            >)
          </li>
          <li>
            FIREFLY MONTE CARLO: EXACT MCMC WITH SUBSETS OF DATA (<a
              href="http://arxiv.org/pdf/1403.5693.pdf"
              >article</a
            >)
          </li>
          <li>
            This is just a small sample. Ideally, find something related to your
            area of research.
          </li>
        </ul>
        <li>
          Include people names and article
          <a
            href="https://docs.google.com/spreadsheets/d/1tV6GgAVmbPyBjQ6OOxSsso011aQwZuyRxJ_1JTuhKY0/edit?usp=sharing"
            >here</a
          >
          <b>by Feb. 26</b>
        </li>
        <li>
          The 1-2 page summary as a .pdf file is
          <span style="text-decoration: underline">due</span> via email.
          Submission date is <b>March 7 by 16:00 CET</b>
        </li>
        <li>
          Presentations will be selected at random and begin during class time
          on March 8. At the discretion of Jason and if needed, some
          presentations will be postponed for a later date.
        </li>
        <li>If you have any questions or concerns email Jason.</li>
      </ul>
    </ul>
    <ul>
      <ul></ul>
      <li>
        <a id="Graded Problem Sets"
          ><span style="text-decoration: underline; font-weight: bold"
            >Graded problem sets</span
          >
          (20%)</a
        >
      </li>
      <ul>
        <li>Problem set 1 (5% of total grade)</li>
        <ul>
          <li>
            Link to
            <a href="https:///ProblemSet1.pdf">problem set assignment</a>
          </li>
        </ul>
        <ul>
          <li>Due: Feb. 14, 2018 by 08:30 CET</li>
        </ul>
        <ul></ul>
        <li>Problem set 2 (15% of total grade)</li>
        <ul>
          <li>
            Link to
            <a href="https:///ProblemSet2_2018.pdf"
              >Problem Set 2 assignment</a
            >
          </li>
          <li>Due: March 23, 2018 by 16:00 CET</li>
          <font color="red"> </font>
        </ul>
      </ul>
    </ul>
    <ul>
      <ul>
        <ul></ul>
      </ul>
      <li>
        <span style="text-decoration: underline; font-weight: bold"
          ><a id="Project" name="Project"></a>Project</span
        >
        (30%)
      </li>
      <ul>
        <li>
          Similar to the oral presentation, this project focuses on using a
          method or statistical treatment that is nominally related to your
          field of research that you or your group select. Unlike the oral
          presentation, the project includes not just understanding and
          explaining the method, but also using it on a some appropriate data
          set of your own choosing.
        </li>
        <li>Can be done alone or in groups of up to 3 people</li>
        <li>
          The only hand-in is a 4-6 page written report. You can submit the code
          as well if you would like.
        </li>
        <li>You may start working on <b>this right now!!</b></li>
      </ul>
    </ul>
    <ul>
      <ul></ul>
      <li>
        <strong
          ><span style="text-decoration: underline; font-weight: bold"
            >Final exam</span
          ></strong
        >
        (40%)
      </li>
      <ul>
        <li>Must work on your own!</li>
        <li>Take home exam</li>
        <ul>
          <li>28 hour between start and submission</li>
          <li>Begins at 10:00 CET on Thursday April 5, 2018</li>
          <li>
            The exam must be submitted by 14:00 CET on&nbsp; Friday April 6,
            2018
          </li>
        </ul>
        <li>The exam will be similar to problem set 2</li>
        <ul>
          <li>
            A handful of more intensive questions as opposed to numerous short
            questions
          </li>
          <li>
            While the exam will contain problems from any portion of the course
            material, the focus will be more on topics in the latter portion of
            the course
          </li>
        </ul>
        <li>
          <a href="https:///ExtraProblems.pdf">Here</a> are two extra practice
          problems similar to what has been on the previous exams
        </li>
        <li>
          Here is a link to the
          <a href="https:///AdvancedMethodsInAppliedStatistics2016/Exam.pdf"
            >2016 exam</a
          >
        </li>
        <li>
          Here is a link to the
          <a
            href="https:///AdvancedMethodsInAppliedStatistics2017/Exam_2017.pdf"
            >2017 exam</a
          >
        </li>
        <ul></ul>
        <ul></ul>
      </ul>
    </ul>
    <ul>
      <li>
        <a id="Extra Credit"><b>Extra Credit</b></a> (+2% to final course grade
        average on a 1-100% scale)
      </li>
      <ul>
        <li>
          2018 NCAA Men's Basketball Bracket submission due by tip-off of
          initial 1st round game on March 15
        </li>
        <li>
          This is NOT a requirement, nor is it an obligation for the course
        </li>
        <li>
          Information can be
          <a href="https:///ExtraCredit_2018.pdf">found here</a>
        </li>
        <li>Due:&nbsp; Thursday March 15 by 17:00 CET</li>
      </ul>
    </ul>
    <ul>
      <ul></ul>
    </ul>
    <hr />
    <h2>Course Syllabus</h2>
    <p>
      The course is 100% likely to change once we begin, and future lectures
      listed below serve as an outline. Even so, we
      <span style="font-weight: bold">are very likely to</span> cover the
      following topics which may require additional software support:
    </p>
    <ul>
      <li>
        Multivariate analysis (MVA) techniques including Boosted Decision Trees
        (BDTs)
      </li>
      <li>The MultiNest bayesian inference tool</li>
      <li>Basis splines</li>
      <li>Markov Chain Monte Carlo</li>
      <li>Likelihood minimization techniques</li>
    </ul>
    <ul></ul>
    Class notes will be posted here:<br />
    <br />
    Class 0 - Pre-Course<br />
    <ul>
      <li>Take a look before the class starts (optional)</li>
      <li><a href="https:///Lecture0_PreTest.pdf">Lecture 0</a></li>
    </ul>
    <hr />
    <b>Class 1 Start (Feb. 6)</b><br />
    <ul>
      <li><a href="https:///CourseInformation.pdf">Course Information</a></li>
      <li>
        <a href="http://kurser.ku.dk/course/nfyk15002u/2017-2018"
          >(description in Kurser)</a
        >
      </li>
      <li>Chi-square</li>
      <li>Code chi-square</li>
      <li>
        Data for exercise 1 (<a href="data/FranksNumbers.txt"
          >FranksNumbers.txt</a
        >)
      </li>
      <li>Review of 'basic' statistics</li>
      <li><a href="https:///Lecture1_Basics_ChiSquare.pdf">Lecture 1</a></li>
      <ul>
        <li>
          <span style="text-decoration: underline"></span>Jason's
          <a href="https:///Exercises/Lecture1_Variance.py">python code</a> for
          exercise 1
        </li>
      </ul>
      <li>Be knowledgeable about the Central Limit Theorem</li>
      <li>
        Start reading paper about how well Gaussian statistics compares to a
        wide selection of scientific measurements
      </li>
      <ul>
        <li>
          "Not Normal: the uncertainties of scientific measurements" link at
          <a href="https://arxiv.org/abs/1612.00778">arXiv</a> or
          <a href="http://rsos.royalsocietypublishing.org/content/4/1/160600"
            >DOI</a
          >
        </li>
        <li>
          We will be discussion the paper in the next class, i.e. on Thursday
        </li>
      </ul>
      <li>
        First problem set
        <b>is <a href="#Graded%20Problem%20Sets">assigned</a></b>
      </li>
    </ul>
    <p><br /></p>
    <hr />
    <ul>
      <ul></ul>
      <ul></ul>
    </ul>
    <b>Class 2 - Monte Carlo Simulation &amp; Least Squares (Feb. 8)</b><br />
    <ul></ul>
    <ul>
      <li><a href="https:///Lecture2_MC_LeastSquares.pdf">Lecture 2</a></li>
      <li>Monte Carlo (reminder that lecture starts at 09:00)</li>
      <li>
        Code for
        <a href="https:///Exercises/Lecture2_CircleArea.py"
          >area of the circle</a
        >
      </li>
      <li>
        From the "Not Normal: the uncertainties of scientific measurements"
        <a href="https://arxiv.org/abs/1612.00778">paper</a>:
      </li>
      <ul>
        <li>
          For the ambitious, create a 'toy monte carlo' of the sample and pair
          distributions for the nuclear physics data in Sec. 2.A. For simplicity
          assume that all the 'quantities' are gaussian distributed
        </li>
        <li>
          Write functions where you can produce multiple gaussian distributions
          to sample from and generate a sample of "12380 measurements, 1437
          quantities, 66677 pairs".
        </li>
        <li>
          Produce the z-distribution (using eq. 4) plot for just your toy monte
          carlo and see if it matches a gaussian, exponential, student-t
          distribution, etc...
        </li>
      </ul>
    </ul>
    <ul>
      <li>Least Squares lecture (starting at 13:00)</li>
      <li>Some useful links</li>
      <ul>
        <li>
          <a href="https://en.wikipedia.org/wiki/Covariance_matrix"
            >Covariance Matrix (wiki)</a
          ><a href="http://stat.ethz.ch/%7Egeer/bsa199_o.pdf"
            ><span style="color: #0000ee"
              ><span style="text-decoration: underline"></span></span
          ></a>
        </li>
        <li>
          <a href="http://stat.ethz.ch/%7Egeer/bsa199_o.pdf"
            ><span style="color: #0000ee"
              ><span style="text-decoration: underline"
                >In-Depth (but still brief) least-squares write-up</span
              ></span
            ></a
          >
        </li>
      </ul>
    </ul>
    <ul>
      <li>
        Discussion of "Not Normal: the uncertainties of scientific measurements"
        (<a href="https://arxiv.org/abs/1612.00778">arXiv</a> or
        <a href="http://rsos.royalsocietypublishing.org/content/4/1/160600"
          >DOI</a
        >)
      </li>
    </ul>
    <p><br /></p>
    <ul></ul>
    <hr />
    <ul></ul>
    <b
      >Class 3 - Introduction to Likelihoods and Numerical Minimizers (Feb.
      13)<br />
    </b>
    <ul>
      <ul></ul>
    </ul>
    <ul></ul>
    <ul></ul>
    <ul>
      <ul></ul>
    </ul>
    <ul>
      <ul></ul>
    </ul>
    <ul></ul>
    <ul>
      <li><a href="https:///Lecture3_General_Likelihood.pdf">Lecture 3</a></li>
      <li>Maximum likelihood method</li>
      <li>Gradient descent and minimizers</li>
      <li>
        Example code from
        <a href="https:///Exercises/Lecture3_likelihood_niccolo.py">Niccolo</a>
        (TA in 2017) and some from
        <a href="https:///Exercises/Lecture3_MLE_Cowan_clean.py">Jason</a>
        (course lecturer)
      </li>
    </ul>
    <ul>
      <li>
        Remember that the
        <a href="#Graded%20Problem%20Sets">first assignment</a> is due on
        <b> Wednesday</b>
      </li>
    </ul>
    <p><br /></p>
    <hr />
    <ul></ul>
    <p>
      <b
        >Class 4 - Intro. to Bayesian Statistics &amp; Splines (Feb. 15)<br />
      </b>
    </p>
    <ul>
      <li>
        <a href="https:///Lecture4_Bayes.pdf">Lecture 4</a> on Simple Bayesian
        statistics
      </li>
      <li>Using priors, posteriors, and likelihoods</li>
      <li>
        Example <a href="https:///Exercises/Lecture4_Bayes_1.py">code</a> for
        exercises from Jason
      </li>
    </ul>
    <ul>
      <li>
        <a href="https:///Lecture4.5_Splines.pdf"
          >Lecture 4.5<span style="color: black"></span
        ></a>
      </li>
      <li>Spliness</li>
      <li>Data files for one of the exercises.</li>
      <ul>
        <li>
          <a href="https:///data/DustLog_forClass.dat"
            >Dust Logger data<br />
          </a>
        </li>
        <li><a href="https:///data/SplineCubic.txt">Spline cubic data</a></li>
        <li>
          <span style="color: #0000ee"
            ><a href="https:///data/SplineOsc1.txt"
              >Spline oscillation data</a
            ></span
          >
        </li>
      </ul>
      <li>Interesting article about use of splines and penalty terms</li>
      <ul>
        <li>
          <a href="https://arxiv.org/pdf/1301.2184v1.pdf">Penalized splines</a>
        </li>
      </ul>
    </ul>
    <p><br /></p>
    <ul></ul>
    <hr />
    <ul></ul>
    <p>
      <b>Class 5 - Background Subtraction and sPlots (Feb. 20)<br /> </b>
    </p>
    <ul>
      <li>
        <a
          href="https:///AdvancedMethodsInAppliedStatistics2018/AdvAppStat18_sWeightsAndPlots.pdf"
          >Lecture 5</a
        >
        (by Troels Peteresen)
      </li>
      <li>
        <a href="https:///data/data_sWeights.txt">Data file</a> for the
        exercises. A separate file is also posted as
        <a href="https:///data/data_sWeights2.txt">data_sWeights2.txt</a>
      </li>
      <li>
        Scripts - <a href="https:///Exercises/sWeights.py">sWeights.py</a> and
        <a href="https:///Exercises/sWeights_solution.py"
          >sWeights_solution.py</a
        >
      </li>
      <li>
        sPlots journal article can be found at
        <a href="https://arxiv.org/abs/physics/0402083"
          >https://arxiv.org/abs/physics/0402083</a
        >
      </li>
    </ul>
    <p><br /></p>
    <ul>
      <li>Some machine learning</li>
      <li>
        There is a
        <a href="https:///ReadMe_TroelsMachine2018.txt">README</a> file which
        contains the location of files and some outline of the research intent
      </li>
      <li>
        Data file is
        <a href="https:///data/MC_SigBkgElectrons_500K_FixedTruth.csv"
          >MC_SigBkgElectrons_500K_FixedTruth.csv</a
        >
      </li>
    </ul>
    <hr />
    <p></p>
    <ul></ul>
    <p>
      <b>Class 6 - Markov Chain(s) (Feb. 22)<br /> </b>
    </p>
    <ul>
      <li>
        Be sure to have an external package for Markov Chain Monte Carlo (MCMC),
        e.g. emcee, PyMC
      </li>
      <ul>
        <li>Just like minimizers, syntax and options matter</li>
        <li>Be familiar with your chosen MCMC package</li>
      </ul>
      <li>
        <a href="https:///Lecture6_MCMC_Bayes.pdf">Lecture 6</a> Markov Chain
        Monte Carlo (MCMC)
      </li>
      <li>Some example python code for the exercises (caveat emptor)</li>
      <ul>
        <li>
          <a
            href="https:///AdvancedMethodsInAppliedStatistics2017/Exercises/Lecture6_MCMC_Example.py"
            >Using PyMC</a
          >, which wasn't the greatest package (at least last year), but it got
          the job done
        </li>
        <li>
          <a
            href="https:///AdvancedMethodsInAppliedStatistics2017/Exercises/Lecture6_MCMC_Example1_Niccolo.py"
            >Using emcee</a
          >, the solution is graciously provided by Niccolo Maffezzoli (2017 TA)
        </li>
      </ul>
    </ul>
    <p><br /></p>
    <hr />
    <p></p>
    <ul>
      <ul></ul>
    </ul>
    <p>
      <b>Class 7 - Parameter Estimation and Confidence Intervals (Feb. 27)</b>
    </p>
    <ul>
      <li>
        <a href="https:///Lecture7_ConfidenceIntervals.pdf">Lecture 7</a>
        Confidence intervals
      </li>
      <li>Numerical minimizers for best-fit values</li>
      <li>
        <a
          href="http://www.nbi.dk/%7Ekoskinen/Teaching/AdvancedMethodsInAppliedStatistics2016/Exercises/MLE_Variance_data.txt"
          >Data file</a
        >
        for one of the exercises (<a
          href="https:///data/Lecture7_MLE_Variance_data_2.txt"
          >extra data file</a
        >)
      </li>
    </ul>
    <ul>
      <li>
        Reminder: oral presentation and 1-2 page article reports will be
        due/covered March 7 and 8 (<a href="#OralPresentation">look here</a>)
      </li>
      <ul>
        <li>
          <a href="https://arxiv.org/abs/1701.02596">Article about Supernova</a>
          first detection time. Look at the caption for the Supplementary Fig. 8
        </li>
      </ul>
    </ul>
    <hr />
    <p></p>
    <ul>
      <ul></ul>
    </ul>
    <p><b>Class 8 - Hypothesis Testing (March 1)</b></p>
    <ul>
      <li><a href="https:///Lecture8_HypothesisTests.pdf">Lecture 8</a></li>
      <li>Likelihood ratio</li>
      <li>
        Data files for one of the exercises. Just use the first column in each
        file. The second column is unimportant.
      </li>
      <ul>
        <li>
          <a href="https:///data/Lecture8_LLH_Ratio_2_data.txt">Data set 1</a>
        </li>
        <li>
          <a href="https:///data/Lecture8_LLH_Ratio_2a_data.txt">Data set 2</a>
        </li>
      </ul>
    </ul>
    <ul>
      <ul></ul>
    </ul>
    <hr />
    <ul>
      <ul></ul>
    </ul>
    <p></p>
    <p><b>Class 9 - Statistical Hypothesis Tests</b><b> (March 6)</b></p>
    <ul>
      <li>Guest lecture by Markus Ahlers</li>
      <li><a href="https:///Lecture9_Ahlers.pdf">Lecture slides</a></li>
      <li>Files and some example code</li>
      <ul>
        <li>
          Data files in .FITS format:
          <a href="https:///data/eventmap1.fits">eventmap1.fits</a> and
          <a href="https:///data/truemap1.fits">truemap1.fits</a>
        </li>
        <li>
          Some example code (all in python):
          <a href="https:///Exercises/C1_produce.py">C1_produce.py</a>
          <a href="https:///Exercises/C1_show.py">C1_show.py</a>
          <a href="https:///Exercises/KS_produce.py">KS_produce.py</a>
          <a href="https:///Exercises/KS_show.py">KS_show.py</a>
          <a href="https:///Exercises/maxLH_produce.py">maxLH_produce.py</a>
          <a href="https:///Exercises/maxLH_show.py">maxLH_show.py</a>
          <a href="https:///Exercises/powerspectrum.py">powerspectrum.py</a>
          <a href="https:///Exercises/twopoint.py">twopoint.py</a>
          <a href="https:///Exercises/Ylm.py">Ylm.py</a>
        </li>
      </ul>
      <li>
        <b>Be sure </b>to have
        <a href="https://healpix.jpl.nasa.gov">HEALPix software</a> installed on
        your computer. There are options for C, C++, JAVA, Python, and I see
        some MATLAB too.<br />
      </li>
    </ul>
    <hr />
    <p></p>
    <p>
      <b
        >Class 10 - Presentations and Multivariate Analysis techniques (March
        8)</b
      >
    </p>
    <ul>
      <li>
        In the morning we will have the oral presentations from the articles
        chosen
      </li>
      <ul>
        <li>
          Links to some to some of the presentations (<a
            href="https:///AdvancedMethodsInAppliedStatistics2016/Presentations_2016.html"
            >2016</a
          >,
          <a
            href="https:///AdvancedMethodsInAppliedStatistics2017/StudentPresentations2017.html"
            >2017</a
          >)
        </li>
      </ul>
    </ul>
    <p>
      The following lecture will be covered on March 15 in the afternoon. It had
      to be postponed due to the in-class student presentations and follow-up
      discussions.
    </p>
    <ul>
      <ul></ul>
      <li><a id="BDT">Boosted Decision Trees</a></li>
      <li><a href="https:///Lecture10_MVA.pdf">Lecture 10</a></li>
      <li>Data</li>
      <ul>
        <li>
          Exercise 1 (<a href="https:///data/BDT_signal_train.txt"
            >training signal</a
          >,
          <a target="_top" href="https:///data/BDT_background_train.txt"
            >training background</a
          >, <a href="https:///data/BDT_signal_test.txt">testing signal</a>,
          <a href="https:///data/BDT_background_test.txt">testing background</a
          >)
        </li>
      </ul>
      <ul>
        <li>
          Exercise 2 (16 variable
          <a href="https:///data/BDT_16var.txt">file</a>)
        </li>
        <ul>
          <li>
            The first column is the index, hence there are 17 'variables', but
            the index variable only for book keeping and has no impact on
            whether an event is signal or background.
          </li>
          <li>
            Every even row is the 'signal' and every odd row is the
            'background'. Thus, there are two rows for each index in the first
            column: the first is the signal and the second is the background.
            [Format is odd, but I got it from a colleague].
          </li>
        </ul>
        <li>
          <a id="BDT Solution Data">Here</a> is the solution data sets separated
          into two files (<a href="https:///data/benign_true.txt">benign</a>
          and <a href="https:///data/malignant_true.txt">malignant</a>) for the
          last exercise of the lecture. Here is also the&nbsp;<a
            href="https:///AdvancedMethodsInAppliedStatistics2017/Exam2_Problem_BDT_CheckSolutions_2016.py"
            >(python) code</a
          >
          that I used to establish the efficiency for all the submissions from
          all the students
        </li>
      </ul>
    </ul>
    <hr />
    <ul>
      <ul>
        <ul></ul>
      </ul>
    </ul>
    <p>
      <b>Class 11 - Data Driven Density Estimation (non-parametric)</b>
      <b>(March 13)</b>
    </p>
    <ul>
      <li>Kernel Density estimation</li>
      <li><a href="https:///Lecture11_KDE.pdf">Lecture 11</a></li>
    </ul>
    <hr />
    <b>Class 12 - </b
    ><b>Confidence Intervals, Failures, and Feldman-Cousins (March 15)</b>
    <ul></ul>
    Note that because of the change in schedule, this will be a
    <b>long day</b> with activities and course material probably using all the
    time from 09:00-12:00 and 13:00-17:00. Bring snacks!<br />
    <ul>
      <li><a href="https:///FC.pdf">Guest lecture</a> by Dr. Morten Medici</li>
      <li>Under/over coverage in hypothesis tests</li>
      <li>
        Flip-flopping confidence intervals and corrections via ranking and use
        of Feldman-Cousins unified approach
      </li>
      <ul>
        <li>
          <a href="https://arxiv.org/abs/physics/9711021">Paper</a> about
          unified approach by G. Feldman and R. Cousins
        </li>
      </ul>
    </ul>
    <ul>
      <li>
        We will cover the Multivariate Analysis techniques, specifically
        <a href="#BDT">Boosted Decision Trees</a> originally intended for
        <b>Class 10</b> in the afternoon.
      </li>
    </ul>
    <p></p>
    <ul></ul>
    <hr />
    <p></p>
    <ul></ul>
    <p>
      <b
        >Class 13 - Nested Sampling, Bayesian Inference, and MultiNest (March
        20)</b
      >
    </p>
    <ul>
      <li><a href="https:///Lecture13_MultiNest.pdf">Lecture 13</a></li>
      <li>
        External packages for conducting nested sampling, e.g. MultiNest, are
        necessary and some python options are:
      </li>
      <ul>
        <li>
          pymultinest (<a
            href="../../../../johannesbuchner.github.io/PyMultiNest/index.html"
            >https://johannesbuchner.github.io/PyMultiNest/</a
          >)
        </li>
        <li>
          nestle (<a href="http://kbarbary.github.io/nestle/"
            >http://kbarbary.github.io/nestle/</a
          >)
        </li>
        <li>
          SuperBayeS (<a
            href="http://www.ft.uam.es/personal/rruiz/superbayes/?page=main.html"
            >http://www.ft.uam.es/personal/rruiz/superbayes/?page=main.html</a
          >)
        </li>
      </ul>
      <li>Very good articles that are easy to read</li>
      <ul>
        <li>
          Excellent and readable paper by developer John Skilling on nested
          sampling (<a
            href="http://www.inference.phy.cam.ac.uk/bayesys/nest.pdf"
            >http://www.inference.phy.cam.ac.uk/bayesys/nest.pdf</a
          >)
        </li>
        <ul>
          <li>
            Read up until the section "The Density of States". There will be a
            <b>discussion at the end of class</b>.
          </li>
        </ul>
        <li>MultiNest academic papers</li>
        <ul>
          <li>
            <a href="http://arxiv.org/abs/0809.3437"
              >http://arxiv.org/abs/0809.3437</a
            >
          </li>
          <li>
            <a href="http://arxiv.org/abs/1306.2144"
              >http://arxiv.org/abs/1306.2144</a
            >
          </li>
        </ul>
      </ul>
    </ul>
    <hr />
    <p>
      <b>Class 14 - Work on Project (no lecture or new material)<br /> </b>
    </p>
    <ul></ul>
    <hr />
    <p>
      <b>Class 15 - </b
      ><b
        ><b
          >Course Review, Discussion on Frequentist and Bayesian concepts, and </b
        >Non-Parametric Tests Lecture snippet (April 3)<br />
      </b>
    </p>
    <ul>
      <li>
        <a href="https:///Lecture_Review.pdf">Review and recap</a> of a few
        topics covered in the course
      </li>
      <li>Discussion about some Frequentist and Bayesian concepts</li>
    </ul>
    <br />
    <ul>
      <li>
        The <a href="#Project">written project</a> accounting for 30% of the
        total course grade is due on April 3
      </li>
      <li>
        <a href="https:///Lecture15_Nonparameteric.pdf">Lecture 15</a> (EXTRA)
      </li>
      <ul>
        <li>Kolmogorov-Smirnov, Anderson-Darling, and Mann-Whitney U tests</li>
        <li><i>Won't be be covered in class</i></li>
        <li>Topics include things that may be useful for research</li>
      </ul>
    </ul>
    <p></p>
    <ul></ul>
    <br />
    <p>
      Extra Projects of a more difficult nature, for those who want something
      more challenging.
    </p>
    <ul>
      <li>
        <a href="../AdvancedMethodsInAppliedStatistics2016/ProblemFromMIT.pdf"
          >Parameter Goodness-of-fit</a
        >
        (PG) in Global physics fits
      </li>
    </ul>
    <dl></dl>
  </body>
</html>
