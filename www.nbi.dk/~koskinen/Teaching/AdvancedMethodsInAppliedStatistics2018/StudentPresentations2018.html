<!DOCTYPE html><html>  <head>    <meta content="text/html; charset=UTF-8" http-equiv="content-type">    <title>StudentPresentations2018</title>  </head>  <body>Student Presenations for Advanced Methods in Applied Statistics 2018<br>    <br>    Training Feedforward Neural Networks Using Genetic Algorithms    <p> </p>    <p> </p>    <p> </p>    <ul>      <li>        <p> </p>        <p> Combining dependent p-values with an empirical adaptation of Browns'          method (<a href="StudentPresentations/Oral%20presentation%20Slides,%20Loui%20Wentzel%20(vln585)%20and%20Christian%20Starup%20(plf981).pdf">presentation</a>,          <a href="StudentPresentations/Oral%20presentation%20Write-up,%20Loui%20Wentzel%20(vln585)%20and%20Christian%20Starup%20(plf981).pdf">write-up</a>)</p>        <p> </p>      </li>    </ul>    <p> </p>    <ul>      <li>        <p> </p>        <p> Bayes factors: Evaluating evidence for models (<a href="StudentPresentations/Bayes_factor_JSJslides.pdf">presentation</a>,          <a href="StudentPresentations/Bayes_factors_Jonas_S_Juul.pdf">write-up</a>)</p>        <p> </p>      </li>    </ul>    <p> </p>    <ul>      <li>        <p> </p>        <p> NoiseOut: A Simple Way to Prune Neural Networks (<a href="StudentPresentations/presentation_pruning_neural_network.pdf">presentation</a>,          <a href="StudentPresentations/Pruning_Neural_Network.pdf">write-up</a>)</p>        <p> </p>      </li>    </ul>    <p> </p>    <ul>      <li>        <p> </p>        <p> Optimal design, Robustness, and Risk Aversion (<a href="StudentPresentations/Optimal%20design,%20Robustness%20and%20Risk%20Aversion.pdf">presentation</a>,          <a href="StudentPresentations/ArticleSummary_StorehaugDetha.pdf">write-up</a>)</p>        <p> </p>      </li>    </ul>    <p> </p>    <ul>      <li>        <p> </p>        <p> The L-curve and its use in the numerical treatment of inverse          problems - treasure chest (<a href="StudentPresentations/L_curve_by_ChristianHolme.pdf">presentation</a>,          <a href="StudentPresentations/Summary_ChristianHolme.pdf">write-up</a>)</p>        <p> </p>      </li>    </ul>    <p> </p>    <ul>      <li>        <p> </p>        <p> Selecting the Number of States in Hidden Markov Models - Pitfalls,          Practical Challenges and Pragmatic Solutions (<a href="StudentPresentations/HMM%20presentation_SimonJohannes.pdf">presentation</a>,          <a href="StudentPresentations/Hidden_Markov_Model__Advanced_Methods_Simon_Johannes.pdf">write-up</a>)</p>        <p> </p>      </li>    </ul>    <p> </p>    <ul>      <li>        <p> </p>        <p>Power-Law Distributions in Empirical Data (<a href="StudentPresentations/xvm706-presentation.pdf">presentation</a>,          <a href="StudentPresentations/xvm706-article-summary.pdf">write-up</a>)          There was some interesting discussion about the applicability of some          of the results from the paper; notably the lack of underfluctations in          \alpha reproduced in slide 11, as well as the criteria that the          x_{min} should be placed when the distribution is a power-law seems          like a self-fulfilling prophecy. If we set the x_{min} where the          distribution exhibits power-law behavior, then it will exhibit          power-law behavior. Maybe everything is okay, but it's still good to          be critical and ask questions :-)</p>        <p> </p>      </li>    </ul>    <p> </p>    <ul>      <li>        <p>Sum of Weighted Poisson Events ( <a href="StudentPresentations/SummedPoissonWeightsPresentation.pdf">presentation</a>,          <a href="StudentPresentations/ArticleWriteUp_EsbenRasmussen_LukasEhrke.pdf">write-up</a>)</p>      </li>    </ul>    <ul>      <li>        <p>Gaussian Process ( <a href="StudentPresentations/GaussianProcessSlides.html">presentation</a>,          <a href="StudentPresentations/Summary%20-%20Mathias%20Engel%20-%20Gaussian%20Processes.pdf">write-up</a>)</p>      </li>      <li>        <p>Bayesian Blocks ( <a href="StudentPresentations/BayBlockBeamer.pdf">presentation</a>,          <a href="StudentPresentations/Sofie_Ida_OrPres.pdf">write-up</a>)</p>      </li>      <li>        <p>Ensemble Samplers with Affine Invariance [EMCEE walkers] (          presentation (<a href="StudentPresentations/affine%20trans.pdf">PDF</a>,          <a href="StudentPresentations/affine%20trans.pptx">powerpoint</a>), <a            href="StudentPresentations/ensemble-samplers-affine-2.pdf">write-up</a>)</p>      </li>      <li>        <p>Frequentism and Bayesianism: A Python-driven Primer ( <a href="StudentPresentations/FreqBayes_Presentation.pdf">presentation</a>,          <a href="StudentPresentations/FreqBayes_Article_summary.pdf">write-up</a>)</p>      </li>      <li>Training Feedforward Neural Networks Using Genetic Algorithms (        presentation (<a href="StudentPresentations/Training%20Feedforward%20Neural%20Networks%20Using%20Genetic%20Algorithms%20(2).pdf">PDF</a>,        <a href="StudentPresentations/Training%20Feedforward%20Neural%20Networks%20Using%20Genetic%20Algorithms%20(2).pptx">powerpoint</a>),
        <a href="StudentPresentations/Training%20Feedforward%20Neural%20Networks%20Using%20Genetic%20Algorithms_Write-up.pdf">write-up</a>)</li>    </ul>    <p> </p>    <br>  </body></html>